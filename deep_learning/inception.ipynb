{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception network\n",
    "\n",
    "![](../img/inception_1.png)\n",
    "\n",
    "Bức ảnh trên mô tả về cấu trúc của inception layer. Trong đó từ (28, 28, 192) input ta sẽ thực hiện đưa lần lượt input qua các conv và pool layer gồm:\n",
    "\n",
    "- 1x1 conv same => output (28, 28, 64)\n",
    "- 3x3 conv same => output (28, 28, 128)\n",
    "- 5x5 conv same => ouput (28, 28, 32)\n",
    "- max-pool (same) => output (28, 28 , 32)\n",
    "\n",
    "Stack các kết quả lại với nhau được 1 outout có số chiều là (28, 28, 256)\n",
    "\n",
    "## I. Vấn đề về computation cost\n",
    "\n",
    "Xét việc áp 5x5 same conv lên input ta có:\n",
    "\n",
    "![](../img/inception_2.png)\n",
    "\n",
    "Ta cần sử dụng 32 bộ filter (5x5x192) để thực hiện convolution cho input (28x28x32)\n",
    "\n",
    "=> cost = 28x28x32 * 5x5x192 = 120M phép nhân\n",
    "\n",
    "Đây là 1 con số rất lớn.\n",
    "\n",
    "Tuy nhiên ta có thể giảm thiếu cost trên bằng cách sử dụng thêm 1x1 same conv như sau:\n",
    "\n",
    "![](../img/inception_3.png)\n",
    "\n",
    "Bằng cách sử dụng 1x1 same conv (gọi là bottleneck layer) ta thấy rắng computation cost giảm xuống còn 12.4M\n",
    "\n",
    "## II. Inception module\n",
    "\n",
    "Giải quyết vấn đề về computation cost như trên cho nên ta sẽ không sử dụng convolution trực tiếp mà sẽ cho đi qua 1x1 same conv layer như sau:\n",
    "\n",
    "![](../img/inception_4.png)\n",
    "\n",
    "## III. GoogleNet\n",
    "\n",
    "![](../img/inception_5.png)\n",
    "\n",
    "Đây là cấu trúc của mạng GoogLeNet, ta thấy rằng mạng đang sử dụng nhiều Inception layer.\n",
    "Bên cạnh đó ở một số hidden Inception layer còn có Fully connected layer và softmax => Để dựng đoán labels hay ta có thể nói răng việc sử dụng mạng này cho phép ta dự đoán labels ở bất kì layer nào. Việc sử dụng như vậy giúp ngăn việc overfitting\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
